{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train and test data and manually name their columns\n",
    "col_name = ['age','workclass','fnlwgt','education','education_num','marital_status','occupation',\n",
    "            'relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country',\n",
    "            'income']\n",
    "data=pd.read_csv('adult.data',names=col_name)\n",
    "test=pd.read_csv('adult.test',names=col_name,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdelrahman Abdullah\\python\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#merge the features data (x) to encode it with the same number of columns then split it again to x_train and x_test\n",
    "full=pd.concat([data, test], axis=0,ignore_index=True)\n",
    "x_full= full.drop('income', axis=1)\n",
    "categorical_columns = x_full.select_dtypes(exclude=[np.number]).columns\n",
    "numerical_columns = x_full.select_dtypes(include=[np.number]).columns\n",
    "encoder = OneHotEncoder(drop='first',sparse=False)\n",
    "encoded_data = encoder.fit_transform(x_full[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "x_full = pd.concat([x_full[numerical_columns], encoded_df], axis=1)\n",
    "x_train=x_full.iloc[:data.shape[0],:].reset_index(drop=True)\n",
    "x_test=x_full.iloc[data.shape[0]:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the target variables (y) and transform it to one true or false column ( >50K) for both y_train and y_test\n",
    "y_train= pd.get_dummies(data['income']).drop(' <=50K', axis=1)\n",
    "y_test= pd.get_dummies(test['income']).drop(' <=50K.', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abdelrahman Abdullah\\python\\Lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#fit the data using train data and use the model to predict target variable for test data\n",
    "classifier= GaussianNB()\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensetivity=  0.3049921996879875\n",
      "specificity=  0.9474827087019463\n"
     ]
    }
   ],
   "source": [
    "#create a confusion matrix using predicted data and actual data to calculate senstivity and specificty\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "senstivity= tp/(tp+fn)\n",
    "specificity= tn/(tn+fp)\n",
    "print(\"sensetivity= \",senstivity)\n",
    "print(\"specificity= \",specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability:\n",
      " [[9.84756080e-01 1.52439199e-02]\n",
      " [9.93541986e-01 6.45801379e-03]\n",
      " [3.22103629e-12 1.00000000e+00]\n",
      " ...\n",
      " [9.78079367e-01 2.19206332e-02]\n",
      " [1.21026493e-05 9.99987897e-01]\n",
      " [9.71722872e-01 2.82771280e-02]]\n"
     ]
    }
   ],
   "source": [
    "#calculate posterior probability\n",
    "print(\"probability:\\n\",classifier.predict_proba(x_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
